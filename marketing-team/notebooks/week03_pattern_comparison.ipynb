{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f4ed64",
   "metadata": {},
   "source": [
    "# Marketing Team - Week 03: Prompt Pattern Comparison\n",
    "\n",
    "This notebook evaluates how different prompting strategies and orchestration patterns affect content quality and alignment. We test Prompting strategies (zero-shot, few-shot, and chain-of-thought / CoT) and Orchestration patterns (single-pass, reflection, and evaluator→optimizer — evaluate → optimize → re-evaluate).\n",
    "\n",
    "---\n",
    "\n",
    "## What We're Testing\n",
    "\n",
    "- Prompting strategies: zero-shot, few-shot, and chain-of-thought (CoT) — different example/template and reasoning scaffolds\n",
    "- Orchestration patterns: single-pass, reflection, and evaluator→optimizer loops (automated evaluation + targeted re-generation)\n",
    "- Formats: LinkedIn short posts, LinkedIn long posts, Blog posts, Facebook posts\n",
    "- Conditions: With and without RAG context; different template styles and CoT depth\n",
    "- Metrics: Brand alignment, factual accuracy, tone consistency, reasoning transparency, and simple engagement proxies\n",
    "\n",
    "**Architecture**: optional RAG context — DocumentLoader → RAGHelper → VectorStore → PromptBuilder → LLM (with orchestration loop)\n",
    "\n",
    "---\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "### Prerequisites\n",
    "- Python 3.10+\n",
    "- `.env` file with API keys (see `.env.example`)\n",
    "- Virtual environment in workspace root\n",
    "\n",
    "### Required Environment Variables\n",
    "```\n",
    "# OpenRouter\n",
    "OPENROUTER_API_KEY=sk-...           \n",
    "\n",
    "# Azure\n",
    "AZURE_OPENAI_ENDPOINT=https://...   \n",
    "AZURE_OPENAI_API_KEY=...\n",
    "AZURE_OPENAI_API_VERSION=...\n",
    "\n",
    "# Web search\n",
    "TAVILY_API_KEY=...                  \n",
    "\n",
    "# LangSmith Configuration\n",
    "LANGSMITH_TRACING_V2=true\n",
    "LANGSMITH_API_KEY=...\n",
    "LANGSMITH_PROJECT=levelup360-marketing-team\n",
    "LANGSMITH_ENDPOINT=https://api.smith.langchain.com\n",
    "\n",
    "# Pricing Configuration\n",
    "GPT4O_INPUT_PRICE_PER_1K=...\n",
    "GPT4O_OUTPUT_PRICE_PER_1K=...\n",
    "EMBEDDING_PRICE_PER_1K=...\n",
    "TAVILY_PRICE_PER_CALL=...\n",
    "```\n",
    "\n",
    "### One-Time Setup (PowerShell)\n",
    "```powershell\n",
    "# From workspace root (this repo):\n",
    "python -m venv .venv\n",
    ".\\\\.venv\\\\Scripts\\\\Activate.ps1\n",
    "\n",
    "# If activation is blocked, run once as admin to allow scripts:\n",
    "Set-ExecutionPolicy -Scope CurrentUser RemoteSigned\n",
    "\n",
    "# Upgrade packaging tooling\n",
    "python -m pip install --upgrade pip setuptools wheel\n",
    "\n",
    "# Install project dependencies (unlocked). Prefer installing from requirements.txt\n",
    "if (Test-Path ./requirements.txt) {\n",
    "  pip install -r requirements.txt\n",
    "} else {\n",
    "  pip install openai python-dotenv pydantic pandas pyyaml rich langsmith chromadb tavily-python tiktoken ipykernel logger\n",
    "}\n",
    "```\n",
    "\n",
    "## Notebook Flow\n",
    "\n",
    "1. **1. Setup** \n",
    "   - Import modules, initialize LLM/embedding clients and basic utilities.\n",
    "2. **2. RAG** \n",
    "   - Initialize RAG components (DocumentLoader, RAGHelper, VectorStore). Optional retrieval context for some runs.\n",
    "3. **3. Prompt Builder Initialization** \n",
    "   - Initialize external search client and `PromptBuilder`, and load brand configuration. (No prompts constructed here.)\n",
    "4. **4. Content Generation & Pattern Comparison** \n",
    "   - Initialize `ContentGenerator`, load topic seeds and run the pattern comparison experiments; save outputs and compute quick evaluation metrics.\n",
    "\n",
    "**Data directories**:\n",
    "- `configs/` - Brand YAML file\n",
    "- `data/chroma_db/` - Persistent vector store\n",
    "- `data/past_posts/` - Past Posts used for RAG\n",
    "- `data/test_topics` - Test topics for generation and pattern comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fea5f6",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Import modules and initialize clients (LLM, embeddings, cost tracking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from rich import print as rprint\n",
    "from statistics import mean\n",
    "import yaml\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Add marketing_team/src to path\n",
    "current_dir = Path.cwd()\n",
    "src_path = current_dir.parent / \"src\"\n",
    "if src_path.exists() and str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import all modules\n",
    "from utils.llm_client import LLMClient\n",
    "from rag.vector_store import VectorStore\n",
    "from rag.rag_helper import RAGHelper\n",
    "from search.tavily_client import TavilySearchClient\n",
    "from prompts.templates import (\n",
    "    LINKEDIN_POST_ZERO_SHOT,\n",
    "    LINKEDIN_POST_FEW_SHOT,\n",
    "    LINKEDIN_LONG_POST_ZERO_SHOT,\n",
    "    LINKEDIN_LONG_POST_FEW_SHOT,\n",
    "    BLOG_POST,\n",
    "    NEWSLETTER,\n",
    "    FACEBOOK_POST_ZERO_SHOT,\n",
    "    FACEBOOK_POST_FEW_SHOT\n",
    ")\n",
    "from prompts.prompt_builder import PromptBuilder\n",
    "from generation.generator import ContentGenerator\n",
    "\n",
    "rprint(\"[green]✓ All modules imported[/green]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9eeb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM clients\n",
    "# Suppress LangSmith warnings if tracing fails\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='langsmith')\n",
    "\n",
    "completion_client = LLMClient()\n",
    "completion_client.get_client(\"openrouter\")\n",
    "\n",
    "embedding_client = LLMClient()\n",
    "embedding_client.get_client(\"azure\")\n",
    "\n",
    "rprint(\"[green]✓ LLM clients initialized[/green]\")\n",
    "rprint(\"[dim]Note: LangSmith tracing errors can be safely ignored[/dim]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d7f3f",
   "metadata": {},
   "source": [
    "## 2. RAG\n",
    "\n",
    "Optionally include RAG context. This section initializes RAG components used for runs that include contextual retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAG components\n",
    "\n",
    "rag_helper = RAGHelper(\n",
    "    embedding_client=embedding_client,\n",
    "    embedding_model=\"text-embedding-3-small\",\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=30,\n",
    "    chunk_threshold=150\n",
    ")\n",
    "\n",
    "persist_dir = current_dir.parent / \"data\" / \"chroma_db\"\n",
    "if not persist_dir.exists():\n",
    "    raise FileNotFoundError(f\"Vector DB not found at {persist_dir} – refusing to create a new one\")\n",
    "\n",
    "vector_store = VectorStore(str(persist_dir))\n",
    "\n",
    "collection_name = \"marketing_content\"\n",
    "\n",
    "rprint(\"[green]✓ RAG components initialized[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e70d5ae",
   "metadata": {},
   "source": [
    "## 3. Prompt Builder Initialization\n",
    "\n",
    "This cell initializes the external search client and the `PromptBuilder`, and loads the brand configuration used by later prompt construction and generation steps. It does not build or run any prompts for the different patterns — prompt construction happens later when we prepare pattern-specific templates and few-shot examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize prompt builder\n",
    "\n",
    "tavily_client = TavilySearchClient()\n",
    "prompt_builder = PromptBuilder(vector_store, rag_helper, tavily_client)\n",
    "\n",
    "# Load brand config\n",
    "\n",
    "brand_config_path = current_dir.parent / \"configs\" / \"itconsulting.yaml\"\n",
    "with open(brand_config_path, 'r', encoding='utf-8') as f:\n",
    "    brand_config = yaml.safe_load(f)\n",
    "\n",
    "topic = \"What are the most effective strategies for scaling enterprise cloud migrations while ensuring security, compliance, and cost control?\"\n",
    "brand = \"itconsulting\"\n",
    "\n",
    "rprint(f\"[green]✓ Prompt builder ready for brand: {brand_config['name']}[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708ea788",
   "metadata": {},
   "source": [
    "## 4. Content Generation & Pattern Comparison\n",
    "\n",
    "Initialize content generator, load topic seeds and run the pattern comparison experiments; save outputs and compute quick evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd60631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator \n",
    "\n",
    "generator = ContentGenerator(\n",
    "    llm_client=completion_client,\n",
    "    vector_store=vector_store,\n",
    "    rag_helper=rag_helper,\n",
    "    brand_config=brand_config,\n",
    "    collection_name=collection_name,\n",
    "    search_client=tavily_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load topics\n",
    "\n",
    "# Load itconsulting topics\n",
    "itconsulting_topics_path = current_dir.parent / \"data\" / \"test_topics\" / \"itconsulting.yaml\"\n",
    "with open(itconsulting_topics_path, 'r', encoding='utf-8') as f:\n",
    "    topics_data = yaml.safe_load(f)\n",
    "\n",
    "# LinkedIn posts\n",
    "linkedin_post_topics = [item['topic'] for item in topics_data['linkedin_posts']]\n",
    "\n",
    "# LinkedIn long posts\n",
    "linkedin_long_post_topics = [item['topic'] for item in topics_data['linkedin_long_posts']]\n",
    "\n",
    "# Blog posts\n",
    "blog_post_topics = [item['topic'] for item in topics_data['blog_posts']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc637c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and temperature\n",
    "\n",
    "model = \"anthropic/claude-sonnet-4\"\n",
    "temperature = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ca073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate content with Pattern 1: Single-pass\n",
    "\n",
    "results_posts = generator.generate_batch(\n",
    "    topics=linkedin_post_topics,\n",
    "    pattern=\"single_pass\",\n",
    "    include_rag=False,\n",
    "    include_search=False,\n",
    "    content_type=\"linkedin_post\",\n",
    "    model=model,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "results_long_posts = generator.generate_batch(\n",
    "    topics=linkedin_long_post_topics,\n",
    "    pattern=\"single_pass\",\n",
    "    max_iterations=0,\n",
    "    include_rag=False,\n",
    "    include_search=False,\n",
    "    content_type=\"linkedin_long_post\",\n",
    "    model=model,\n",
    "    temperature=temperature\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "results_blog_posts = generator.generate_batch(\n",
    "    topics=blog_post_topics,\n",
    "    pattern=\"single_pass\",\n",
    "    max_iterations=0,\n",
    "    include_rag=False,\n",
    "    include_search=False,\n",
    "    content_type=\"blog_post\",\n",
    "    model=model,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "results_single_pass = [{**item, 'content_type': 'linkedin_post'} for item in results_posts]\n",
    "results_single_pass += [{**item, 'content_type': 'linkedin_long_post'} for item in results_long_posts]\n",
    "results_single_pass += [{**item, 'content_type': 'blog_post'} for item in results_blog_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6247963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print generated content with Pattern 1: Single-pass\n",
    "\n",
    "for i, result in enumerate(results_single_pass):\n",
    "    rprint(\"=\"*60)\n",
    "    rprint(f\"GENERATED POST {i+1}:\")\n",
    "    rprint(\"=\"*60)\n",
    "    rprint(result['content'])\n",
    "    rprint(\"=\"*60)\n",
    "\n",
    "    rprint(f\"\\nCost: €{result['metadata']['cost']:.6f}\")\n",
    "    rprint(f\"Tokens: {result['metadata']['input_tokens']} in / {result['metadata']['output_tokens']} out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ca073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score content generated with single pass and print scoring\n",
    "\n",
    "scored_single_pass = []\n",
    "\n",
    "for result in results_single_pass:\n",
    "    score = generator.score_content(content=result['content'], content_type=result['content_type'], model=model)\n",
    "    scored_single_pass.append(result | score)\n",
    "    scores = f\"\\nContent: {result['content']}\\n\\n\"\n",
    "    scores += f\"  Average score: {score['average_score']}\"\n",
    "    scores += f\"  brand_voice score: {score['brand_voice_score']}\"\n",
    "    scores += f\"  structure score: {score['structure_score']}\"\n",
    "    scores += f\"  accuracy score: {score['accuracy_score']}\"\n",
    "    scores += f\"  violations: {score['violations']}\"\n",
    "    scores += f\"  Reasoning: {score['reasoning']}\"\n",
    "    rprint(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc0e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print averages for single pass\n",
    "\n",
    "single_pass_avg_score = {\"avg_score\": mean([result['average_score'] for result in scored_single_pass])}\n",
    "single_pass_avg_cost = {\"avg_cost\": mean([result['metadata']['cost'] for result in scored_single_pass])}\n",
    "single_pass_avg_latency = {\"avg_latency\": mean([result['metadata']['latency'] for result in scored_single_pass])}\n",
    "\n",
    "rprint(\"=\"*60)\n",
    "rprint(f\"SINGLE PASS PATTERN AVERAGES:\")\n",
    "rprint(\"=\"*60)\n",
    "rprint(f\"\\nAverage score: {single_pass_avg_score['avg_score']:.6f}\")\n",
    "rprint(f\"\\nCost: €{single_pass_avg_cost['avg_cost']:.6f}\")\n",
    "rprint(f\"Latency: {single_pass_avg_latency['avg_latency']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate content with Pattern 2: Reflection\n",
    "\n",
    "results_posts = generator.generate_batch(\n",
    "    topics=linkedin_post_topics,\n",
    "    pattern=\"reflection\",\n",
    "    include_rag=False,\n",
    "    include_search=False,\n",
    "    content_type=\"linkedin_post\",\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    max_iterations=2\n",
    ")\n",
    "\n",
    "results_long_posts = generator.generate_batch(\n",
    "    topics=linkedin_long_post_topics,\n",
    "    pattern=\"reflection\",\n",
    "    include_rag=False,\n",
    "    include_search=False,\n",
    "    content_type=\"linkedin_long_post\",\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    max_iterations=2\n",
    ")\n",
    "\n",
    "results_blog_posts = generator.generate_batch(\n",
    "    topics=blog_post_topics,\n",
    "    pattern=\"reflection\",\n",
    "    include_rag=False,\n",
    "    include_search=False,\n",
    "    content_type=\"blog_post\",\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    max_iterations=2\n",
    ")\n",
    "\n",
    "results_reflection = [{**item, 'content_type': 'linkedin_post'} for item in results_posts]\n",
    "results_reflection += [{**item, 'content_type': 'linkedin_long_post'} for item in results_long_posts]\n",
    "results_reflection += [{**item, 'content_type': 'blog_post'} for item in results_blog_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print generated content with Pattern 2: Reflection\n",
    "\n",
    "for i, result in enumerate(results_reflection):\n",
    "    rprint(\"=\"*60)\n",
    "    rprint(f\"GENERATED POST {i+1}:\")\n",
    "    rprint(\"=\"*60)\n",
    "    rprint(result['content'])\n",
    "    rprint(\"=\"*60)\n",
    "\n",
    "    rprint(f\"\\nCost: €{result['metadata']['cost']:.6f}\")\n",
    "    rprint(f\"Tokens: {result['metadata']['input_tokens']} in / {result['metadata']['output_tokens']} out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de469028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score content generated with reflection\n",
    "\n",
    "scored_reflection = []\n",
    "\n",
    "for result in results_reflection:\n",
    "    score = generator.score_content(content=result['content'], content_type=result['content_type'], model=model)\n",
    "    scored_reflection.append(result | score)\n",
    "    scores = f\"\\nContent: {result['content']}\\n\\n\"\n",
    "    scores += f\"  Average score: {score['average_score']}\"\n",
    "    scores += f\"  brand_voice score: {score['brand_voice_score']}\"\n",
    "    scores += f\"  structure score: {score['structure_score']}\"\n",
    "    scores += f\"  accuracy score: {score['accuracy_score']}\"\n",
    "    scores += f\"  violations: {score['violations']}\"\n",
    "    scores += f\"  Reasoning: {score['reasoning']}\"\n",
    "    rprint(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0436a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print averages for reflection\n",
    "\n",
    "reflection_avg_score = {\"avg_score\": mean([result['average_score'] for result in scored_reflection])}\n",
    "reflection_avg_cost = {\"avg_cost\": mean([result['metadata']['cost'] for result in scored_reflection])}\n",
    "reflection_avg_latency = {\"avg_latency\": mean([result['metadata']['latency'] for result in scored_reflection])}\n",
    "\n",
    "rprint(\"=\"*60)\n",
    "rprint(f\"REFLECTION PATTERN AVERAGES:\")\n",
    "rprint(\"=\"*60)\n",
    "rprint(f\"\\nAverage score: {reflection_avg_score['avg_score']:.6f}\")\n",
    "rprint(f\"\\nCost: €{reflection_avg_cost['avg_cost']:.6f}\")\n",
    "rprint(f\"Latency: {reflection_avg_latency['avg_latency']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate content with Pattern 3: Evaluator-optimizer\n",
    "\n",
    "results_posts = generator.generate_batch(\n",
    "    topics=linkedin_post_topics,\n",
    "    pattern=\"evaluator_optimizer\",\n",
    "    include_rag=False,\n",
    "    include_search=False,\n",
    "    content_type=\"linkedin_post\",\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    max_iterations=2\n",
    ")\n",
    "\n",
    "results_long_posts = generator.generate_batch(\n",
    "    topics=linkedin_long_post_topics,\n",
    "    pattern=\"evaluator_optimizer\",\n",
    "    include_rag=False,\n",
    "    include_search=False,\n",
    "    content_type=\"linkedin_long_post\",\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    max_iterations=2\n",
    ")\n",
    "\n",
    "results_blog_posts = generator.generate_batch(\n",
    "    topics=blog_post_topics,\n",
    "    pattern=\"evaluator_optimizer\",\n",
    "    include_rag=False,\n",
    "    include_search=False,\n",
    "    content_type=\"blog_post\",\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    max_iterations=2\n",
    ")\n",
    "\n",
    "results_eval_optimizer = [{**item, 'content_type': 'linkedin_post'} for item in results_posts]\n",
    "results_eval_optimizer += [{**item, 'content_type': 'linkedin_long_post'} for item in results_long_posts]\n",
    "results_eval_optimizer += [{**item, 'content_type': 'blog_post'} for item in results_blog_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print generated content with Pattern 3: Evaluator-optimizer\n",
    "\n",
    "for i, result in enumerate(results_eval_optimizer):\n",
    "    rprint(\"=\"*60)\n",
    "    rprint(f\"GENERATED POST {i+1}:\")\n",
    "    rprint(\"=\"*60)\n",
    "    rprint(result['content'])\n",
    "    rprint(\"=\"*60)\n",
    "\n",
    "    rprint(f\"\\nCost: €{result['metadata']['cost']:.6f}\")\n",
    "    rprint(f\"Tokens: {result['metadata']['input_tokens']} in / {result['metadata']['output_tokens']} out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score content generated with evaluation optimizer\n",
    "\n",
    "scored_eval_optimizer = []\n",
    "\n",
    "for result in results_eval_optimizer:\n",
    "    score = generator.score_content(content=result['content'], content_type=result['content_type'], model=model)\n",
    "    scored_eval_optimizer.append(result | score)\n",
    "    scores = f\"\\nContent: {result['content']}\\n\\n\"\n",
    "    scores += f\"  Average score: {score['average_score']}\"\n",
    "    scores += f\"  brand_voice score: {score['brand_voice_score']}\"\n",
    "    scores += f\"  structure score: {score['structure_score']}\"\n",
    "    scores += f\"  accuracy score: {score['accuracy_score']}\"\n",
    "    scores += f\"  violations: {score['violations']}\"\n",
    "    scores += f\"  Reasoning: {score['reasoning']}\"\n",
    "    rprint(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56813a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print averages for evaluation optimizer\n",
    "\n",
    "eval_optimizer_avg_score = {\"avg_score\": mean([result['average_score'] for result in scored_eval_optimizer])}\n",
    "eval_optimizer_avg_cost = {\"avg_cost\": mean([result['metadata']['cost'] for result in scored_eval_optimizer])}\n",
    "eval_optimizer_avg_latency = {\"avg_latency\": mean([result['metadata']['latency'] for result in scored_eval_optimizer])}\n",
    "\n",
    "rprint(\"=\"*60)\n",
    "rprint(f\"EVAL OPTIMIZER PATTERN AVERAGES:\")\n",
    "rprint(\"=\"*60)\n",
    "rprint(f\"\\nAverage score: {eval_optimizer_avg_score['avg_score']:.6f}\")\n",
    "rprint(f\"\\nCost: €{eval_optimizer_avg_cost['avg_cost']:.6f}\")\n",
    "rprint(f\"Latency: {eval_optimizer_avg_latency['avg_latency']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all generated content grouped by pattern\n",
    "\n",
    "content = \"\"\n",
    "content += \"=\" * 60 + \"\\n\"\n",
    "content += \"SINGLE PASS GENERATED POSTS\\n\"\n",
    "\n",
    "for i, item in enumerate(results_single_pass, start=1):\n",
    "    content += \"=\" * 60 + \"\\n\"\n",
    "    content += f\"GENERATED POST {i}:\\n\"\n",
    "    content += f\"Content type: {item.get('content_type', '<unknown>')}\\n\"\n",
    "    content += \"-\" * 60 + \"\\n\"\n",
    "    content += item.get(\"content\", \"\") + \"\\n\"\n",
    "    content += \"=\" * 60 + \"\\n\"\n",
    "\n",
    "content += \"=\" * 60 + \"\\n\"\n",
    "content += \"REFLECTION GENERATED POSTS\\n\"\n",
    "\n",
    "for i, item in enumerate(results_reflection, start=1):\n",
    "    content += \"=\" * 60 + \"\\n\"\n",
    "    content += f\"GENERATED POST {i}:\\n\"\n",
    "    content += f\"Content type: {item.get('content_type', '<unknown>')}\\n\"\n",
    "    content += \"-\" * 60 + \"\\n\"\n",
    "    content += item.get(\"content\", \"\") + \"\\n\"\n",
    "    content += \"=\" * 60 + \"\\n\"\n",
    "\n",
    "content += \"=\" * 60 + \"\\n\"\n",
    "content += \"EVAL OPTIMIZER GENERATED POSTS\\n\"\n",
    "\n",
    "for i, item in enumerate(results_eval_optimizer, start=1):\n",
    "    content += \"=\" * 60 + \"\\n\"\n",
    "    content += f\"GENERATED POST {i}:\\n\"\n",
    "    content += f\"Content type: {item.get('content_type', '<unknown>')}\\n\"\n",
    "    content += \"-\" * 60 + \"\\n\"\n",
    "    content += item.get(\"content\", \"\") + \"\\n\"\n",
    "    content += \"=\" * 60 + \"\\n\"\n",
    "\n",
    "rprint(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
