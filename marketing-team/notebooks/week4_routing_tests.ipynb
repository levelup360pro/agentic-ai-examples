{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e343a4e",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "  <a href=\"https://www.linkedin.com/company/100622063\" target=\"_blank\" title=\"Follow LevelUp360 on LinkedIn\">\n",
    "    <img src=\"../../assets/levelup360-inverted-logo-transparent.svg\" alt=\"LevelUp360\" width=\"220\">\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "\n",
    "# Marketing Team – Week 4: content planning agent Routing Tests\n",
    "\n",
    "**Objective:** Validate that the LangGraph content planning agent node correctly routes queries to appropriate tools before building the full workflow.\n",
    "\n",
    "**Pass Criteria:**\n",
    "- Routing accuracy: >90%\n",
    "- Routing consistency: >95%\n",
    "\n",
    "**Test Approach:**\n",
    "1. Define test cases with known correct routing decisions\n",
    "2. Measure routing accuracy across all test cases\n",
    "3. Measure routing consistency (5 runs per case)\n",
    "4. Analyze failures and inconsistencies\n",
    "5. Pass/fail decision based on thresholds\n",
    "\n",
    "**NOTE: Accuracy and consistency results are dependent on the system message you use in brand config YAML (i.e. itconsulting.yaml) models/content_planning/system_message**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8908f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Setup\n",
    "from src.evaluation.routing_evaluator import RoutingEvaluator, LangGraphRoutingAdapter\n",
    "from src.agents.graphs.content_generation_graph import build_content_workflow\n",
    "import pandas as pd\n",
    "from rich import print as rprint\n",
    "\n",
    "# Configuration\n",
    "brand = \"itconsulting\"\n",
    "\n",
    "# Build the graph\n",
    "app = build_content_workflow(brand=brand)\n",
    "\n",
    "# Initialize adapter and evaluator\n",
    "adapter = LangGraphRoutingAdapter(\n",
    "    app=app,\n",
    "    brand=brand,\n",
    "    template=\"LINKEDIN_POST_ZERO_SHOT\",\n",
    "    use_cot=True\n",
    ")\n",
    "\n",
    "evaluator = RoutingEvaluator(adapter)\n",
    "\n",
    "rprint(\"✓ Setup complete\")\n",
    "rprint(f\"  Brand: {brand}\")\n",
    "rprint(f\"  Graph: Content generation workflow compiled\")\n",
    "rprint(f\"  Tools: rag_search, web_search\")\n",
    "rprint(f\"  Adapter: LangGraphRoutingAdapter\")\n",
    "rprint(f\"  Evaluator: RoutingEvaluator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308bb73",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test Cases\n",
    "\n",
    "Defining 20 test cases covering different routing scenarios:\n",
    "- **Company-specific queries** → `rag_search` (needs your documents)\n",
    "- **General knowledge queries** → `direct_generation` (no retrieval needed)\n",
    "- **Current/industry information** → `web_search` (needs current data)\n",
    "- **Mixed queries** → Multiple tools (e.g., `rag_search` + `web_search`)\n",
    "\n",
    "Each test case includes:\n",
    "- `query`: The input topic/question\n",
    "- `expected_tools`: List of tools that should be called (supports single or multiple)\n",
    "- `reason`: Why these tools are expected\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd77ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Test Cases \n",
    "routing_test_cases = [\n",
    "    # Company-specific queries - should use rag_search\n",
    "    {\n",
    "        \"query\": \"Create a post about our AI governance pipeline\",\n",
    "        \"expected_tools\": [\"rag_search\"],  \n",
    "        \"reason\": \"Company-specific implementation details\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Explain how our agentic marketing team works\",\n",
    "        \"expected_tools\": [\"rag_search\"],  \n",
    "        \"reason\": \"Specific technical implementation from our docs\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What services does LevelUp360 offer?\",\n",
    "        \"expected_tools\": [\"rag_search\"],  \n",
    "        \"reason\": \"Company-specific service information\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Describe our Azure cloud architecture approach\",\n",
    "        \"expected_tools\": [\"rag_search\"],  \n",
    "        \"reason\": \"Our specific architecture patterns\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What certifications and expertise do we have?\",\n",
    "        \"expected_tools\": [\"rag_search\"],  \n",
    "        \"reason\": \"Company-specific credentials\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do we implement secure AI infrastructure?\",\n",
    "        \"expected_tools\": [\"rag_search\"],  \n",
    "        \"reason\": \"Our specific security implementation\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is our approach to AI evaluation and governance?\",\n",
    "        \"expected_tools\": [\"rag_search\"],  \n",
    "        \"reason\": \"Company-specific methodology\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Explain our content generation workflow\",\n",
    "        \"expected_tools\": [\"rag_search\"],  \n",
    "        \"reason\": \"Our specific workflow implementation\"\n",
    "    },\n",
    "    \n",
    "    # General knowledge - should use direct_generation (no tools)\n",
    "    {\n",
    "        \"query\": \"Write about the importance of AI governance in general\",\n",
    "        \"expected_tools\": [],\n",
    "        \"reason\": \"General AI governance concepts, no company context needed\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Discuss general cloud security best practices\",\n",
    "        \"expected_tools\": [],\n",
    "        \"reason\": \"General industry knowledge\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Explain what agentic AI systems are\",\n",
    "        \"expected_tools\": [],\n",
    "        \"reason\": \"General AI concept definition\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Write about the benefits of infrastructure as code\",\n",
    "        \"expected_tools\": [],\n",
    "        \"reason\": \"General DevOps concept\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Discuss the role of AI in business transformation\",\n",
    "        \"expected_tools\": [],\n",
    "        \"reason\": \"General business/AI topic\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Explain the concept of retrieval-augmented generation\",\n",
    "        \"expected_tools\": [],\n",
    "        \"reason\": \"General AI architecture concept\"\n",
    "    },\n",
    "    \n",
    "    # Current/industry information - should use web_search\n",
    "    {\n",
    "        \"query\": \"What are the latest trends in AI implementation for 2025?\",\n",
    "        \"expected_tools\": [\"web_search\"],\n",
    "        \"reason\": \"Current industry trends, needs recent information\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What are current cloud security compliance requirements?\",\n",
    "        \"expected_tools\": [\"web_search\"],\n",
    "        \"reason\": \"Current regulatory information\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What are the latest Azure AI services announcements?\",\n",
    "        \"expected_tools\": [\"web_search\"],\n",
    "        \"reason\": \"Current product updates\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What are companies saying about AI ROI in 2025?\",\n",
    "        \"expected_tools\": [\"web_search\"],\n",
    "        \"reason\": \"Current market sentiment and data\"\n",
    "    },\n",
    "    \n",
    "    # Edge cases - mixed signals\n",
    "    {\n",
    "    \"query\": \"Compare our Azure governance approach to current industry standards\",\n",
    "    \"expected_tools\": [\"rag_search\", \"web_search\"],  \n",
    "    \"reason\": \"Needs our approach (RAG) + industry standards (web search)\"\n",
    "    },\n",
    "    {\n",
    "    \"query\": \"How does our agentic system compare to general AI agent frameworks?\",\n",
    "    \"expected_tools\": [\"rag_search\", \"web_search\"],  \n",
    "    \"reason\": \"Needs our system (RAG) + general frameworks (web search)\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Count by tool type\n",
    "single_rag = sum(1 for tc in routing_test_cases if tc['expected_tools'] == ['rag_search'])\n",
    "single_direct = sum(1 for tc in routing_test_cases if tc['expected_tools'] == [])\n",
    "single_web = sum(1 for tc in routing_test_cases if tc['expected_tools'] == ['web_search'])\n",
    "multi_tool = sum(1 for tc in routing_test_cases if len(tc['expected_tools']) > 1)\n",
    "\n",
    "rprint(f\"  Single tool - rag_search: {single_rag}\")\n",
    "rprint(f\"  Single tool - direct_generation: {single_direct}\")\n",
    "rprint(f\"  Single tool - web_search: {single_web}\")\n",
    "rprint(f\"  Multi-tool: {multi_tool}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55047f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test 1: Routing Accuracy\n",
    "\n",
    "Testing if the content planning agent chooses the correct tool(s) for each query type.\n",
    "\n",
    "**Metric:** Percentage of test cases where `actual_tools == expected_tools` (order-independent)\n",
    "\n",
    "**Target:** >90% accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Routing Accuracy Tests\n",
    "rprint(\"Running routing accuracy tests...\")\n",
    "rprint(\"=\" * 60)\n",
    "\n",
    "accuracy_results = evaluator.test_routing_accuracy(routing_test_cases)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = accuracy_results['correct'].mean()\n",
    "\n",
    "rprint(f\"\\n{'=' * 60}\")\n",
    "rprint(f\"ROUTING ACCURACY: {accuracy * 100:.1f}%\")\n",
    "rprint(f\"{'=' * 60}\")\n",
    "rprint(f\"Correct: {accuracy_results['correct'].sum()}/{len(accuracy_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Breakdown by Tool Type\n",
    "rprint(\"\\nAccuracy breakdown:\")\n",
    "rprint(\"-\" * 60)\n",
    "\n",
    "# Helper to categorize test cases\n",
    "def categorize_case(expected_tools):\n",
    "    if len(expected_tools) == 1:\n",
    "        return f\"Single: {expected_tools[0]}\"\n",
    "    else:\n",
    "        return \"Multi-tool\"\n",
    "\n",
    "accuracy_results['category'] = accuracy_results['expected_tools'].apply(\n",
    "    lambda x: categorize_case(x)\n",
    ")\n",
    "\n",
    "by_category = accuracy_results.groupby('category').agg({\n",
    "    'correct': ['sum', 'count', 'mean']\n",
    "}).round(3)\n",
    "\n",
    "by_category.columns = ['Correct', 'Total', 'Accuracy']\n",
    "by_category['Accuracy %'] = (by_category['Accuracy'] * 100).round(1)\n",
    "\n",
    "rprint(by_category[['Correct', 'Total', 'Accuracy %']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad2931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Show Routing Failures\n",
    "failures = accuracy_results[~accuracy_results['correct']]\n",
    "\n",
    "if len(failures) > 0:\n",
    "    rprint(f\"\\n{'=' * 60}\")\n",
    "    rprint(f\"X ROUTING FAILURES: {len(failures)}\")\n",
    "    rprint(f\"{'=' * 60}\\n\")\n",
    "    \n",
    "    for idx, row in failures.iterrows():\n",
    "        rprint(f\"Query: {row['query']}\")\n",
    "        rprint(f\"  Expected: {row['expected_tools']}\")\n",
    "        rprint(f\"  Actual: {row['actual_tools']}\")\n",
    "        rprint(f\"  content planning agent reasoning: {row['reasoning']}\")\n",
    "        rprint(f\"  Why expected: {row['reason_for_expected']}\")\n",
    "        rprint()\n",
    "else:\n",
    "    rprint(f\"\\n{'=' * 60}\")\n",
    "    rprint(\"✓ NO ROUTING FAILURES\")\n",
    "    rprint(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e28f4d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test 2: Routing Consistency\n",
    "\n",
    "Testing if the content planning agent makes the same routing decision across multiple runs.\n",
    "\n",
    "**Metric:** Percentage of test cases where all 5 runs produce the same routing decision\n",
    "\n",
    "**Target:** >95% consistency\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f60306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Routing Consistency Tests\n",
    "rprint(\"Running routing consistency tests (5 runs per case)...\")\n",
    "rprint(\"=\" * 60)\n",
    "\n",
    "consistency_results = evaluator.test_routing_consistency(\n",
    "    routing_test_cases,\n",
    "    num_runs=5\n",
    ")\n",
    "\n",
    "# Calculate overall consistency\n",
    "consistency = consistency_results['consistent'].mean()\n",
    "\n",
    "rprint(f\"\\n{'=' * 60}\")\n",
    "rprint(f\"ROUTING CONSISTENCY: {consistency * 100:.1f}%\")\n",
    "rprint(f\"{'=' * 60}\")\n",
    "rprint(f\"Consistent: {consistency_results['consistent'].sum()}/{len(consistency_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd872d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Inconsistent Routing Cases\n",
    "inconsistent = consistency_results[~consistency_results['consistent']]\n",
    "\n",
    "if len(inconsistent) > 0:\n",
    "    rprint(f\"\\n{'=' * 60}\")\n",
    "    rprint(f\"  INCONSISTENT ROUTING: {len(inconsistent)}\")\n",
    "    rprint(f\"{'=' * 60}\\n\")\n",
    "    \n",
    "    for idx, row in inconsistent.iterrows():\n",
    "        rprint(f\"Query: {row['query']}\")\n",
    "        rprint(f\"  Expected: {row['expected_tools']}\")\n",
    "        rprint(f\"  Decisions across 5 runs:\")\n",
    "        for i, decision in enumerate(row['decisions'], 1):\n",
    "            rprint(f\"    Run {i}: {decision}\")\n",
    "        rprint(f\"  Unique decision patterns: {row['variance']}\")\n",
    "        rprint()\n",
    "else:\n",
    "    rprint(f\"\\n{'=' * 60}\")\n",
    "    rprint(\"✓ ALL ROUTING DECISIONS CONSISTENT\")\n",
    "    rprint(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ecb99",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Analysis and Decision\n",
    "\n",
    "Analyzing results against pass criteria:\n",
    "- **Routing accuracy:** >90%\n",
    "- **Routing consistency:** >95%\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68645e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "analysis = evaluator.analyze_results(\n",
    "    accuracy_results,\n",
    "    consistency_results,\n",
    "    accuracy_threshold=0.90,\n",
    "    consistency_threshold=0.95\n",
    ")\n",
    "\n",
    "rprint(\"=\" * 60)\n",
    "rprint(\"ANALYSIS\")\n",
    "rprint(\"=\" * 60)\n",
    "rprint(f\"\\nAccuracy: {analysis['accuracy'] * 100:.1f}% (threshold: {analysis['thresholds']['accuracy'] * 100:.0f}%)\")\n",
    "rprint(f\"Consistency: {analysis['consistency'] * 100:.1f}% (threshold: {analysis['thresholds']['consistency'] * 100:.0f}%)\")\n",
    "\n",
    "rprint(f\"\\nFailure summary:\")\n",
    "rprint(f\"  Routing failures: {len(analysis['failures'])}\")\n",
    "rprint(f\"  Inconsistent cases: {len(analysis['inconsistent_cases'])}\")\n",
    "\n",
    "if len(analysis['failures']) > 0:\n",
    "    rprint(f\"\\nMost common failure patterns:\")\n",
    "    failure_df = pd.DataFrame(analysis['failures'])\n",
    "    # Show which expected tools had most failures\n",
    "    if 'expected_tools' in failure_df.columns:\n",
    "        rprint(failure_df['expected_tools'].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8286bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Decision\n",
    "rprint(\"\\n\" + \"=\" * 60)\n",
    "rprint(\"FINAL ASSESSMENT\")\n",
    "rprint(\"=\" * 60)\n",
    "\n",
    "if analysis['passes']:\n",
    "    rprint(\"\\n✓ PASS: content planning agent routing is reliable\")\n",
    "    rprint(f\"\\n  Accuracy: {analysis['accuracy'] * 100:.1f}% ✓\")\n",
    "    rprint(f\"  Consistency: {analysis['consistency'] * 100:.1f}% ✓\")\n",
    "    rprint(\"\\nNext steps:\")\n",
    "    rprint(\"  → Proceed to building full LangGraph workflow\")\n",
    "    rprint(\"  → Test end-to-end content quality vs Week 3 baseline\")\n",
    "    rprint(\"  → Validate multi-tool coordination in full workflow\")\n",
    "else:\n",
    "    rprint(\"\\nX FAIL: content planning agent routing needs tuning\")\n",
    "    rprint(\"\\nIssues identified:\")\n",
    "    \n",
    "    if analysis['accuracy'] <= 0.90:\n",
    "        rprint(f\"  → Accuracy too low: {analysis['accuracy'] * 100:.1f}% (target: >90%)\")\n",
    "        rprint(\"     Action: Review failed cases and adjust content planning agent prompt\")\n",
    "        \n",
    "        # Show specific failure patterns\n",
    "        if len(analysis['failures']) > 0:\n",
    "            rprint(\"\\n     Common failure types:\")\n",
    "            failure_df = pd.DataFrame(analysis['failures'])\n",
    "            for _, failure in failure_df.head(3).iterrows():\n",
    "                rprint(f\"       - Expected {failure['expected_tools']}, got {failure['actual_tools']}\")\n",
    "    \n",
    "    if analysis['consistency'] <= 0.95:\n",
    "        rprint(f\"  → Consistency too low: {analysis['consistency'] * 100:.1f}% (target: >95%)\")\n",
    "        rprint(\"     Action: Consider lowering temperature or adjusting routing logic\")\n",
    "    \n",
    "    rprint(\"\\nNext steps:\")\n",
    "    rprint(\"  → Fix identified issues\")\n",
    "    rprint(\"  → Re-run routing tests\")\n",
    "    rprint(\"  → Do not proceed to full workflow until routing passes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b547131",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Save Results\n",
    "\n",
    "Saving test results for documentation and future comparison.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2eda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results to CSV\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"data/week_04\", exist_ok=True)\n",
    "\n",
    "# Save accuracy results\n",
    "accuracy_path = \"data/week_04/routing_accuracy.csv\"\n",
    "accuracy_results.to_csv(accuracy_path, index=False)\n",
    "rprint(f\"✓ Saved accuracy results: {accuracy_path}\")\n",
    "\n",
    "# Save consistency results\n",
    "consistency_path = \"data/week_04/routing_consistency.csv\"\n",
    "consistency_results.to_csv(consistency_path, index=False)\n",
    "rprint(f\"✓ Saved consistency results: {consistency_path}\")\n",
    "\n",
    "# Save summary\n",
    "summary_df = pd.DataFrame([{\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"brand\": brand,\n",
    "    \"accuracy\": analysis['accuracy'],\n",
    "    \"consistency\": analysis['consistency'],\n",
    "    \"passes\": analysis['passes'],\n",
    "    \"failures\": len(analysis['failures']),\n",
    "    \"inconsistent_cases\": len(analysis['inconsistent_cases']),\n",
    "    \"total_test_cases\": len(routing_test_cases),\n",
    "    \"single_tool_cases\": len([tc for tc in routing_test_cases if len(tc['expected_tools']) == 1]),\n",
    "    \"multi_tool_cases\": len([tc for tc in routing_test_cases if len(tc['expected_tools']) > 1])\n",
    "}])\n",
    "\n",
    "summary_path = \"data/week_04/routing_summary.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "rprint(f\"✓ Saved summary: {summary_path}\")\n",
    "\n",
    "rprint(f\"\\nAll results saved to data/week_04/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76fbe5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test Case Details\n",
    "\n",
    "Full details of all test cases for reference and debugging.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Full Results Table\n",
    "rprint(\"Full Accuracy Results:\")\n",
    "rprint(\"=\" * 60)\n",
    "display(accuracy_results[['query', 'expected_tools', 'actual_tools', 'correct', 'category']])\n",
    "\n",
    "rprint(\"\\nFull Consistency Results:\")\n",
    "rprint(\"=\" * 60)\n",
    "display(consistency_results[['query', 'expected_tools', 'actual_decisions', 'consistent', 'unique_decisions', 'mode_decision']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498ffd5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multi-Tool Analysis\n",
    "\n",
    "Specific analysis of multi-tool routing cases (queries requiring multiple tools).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd1f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Tool Specific Analysis\n",
    "multi_tool_cases = accuracy_results[accuracy_results['category'] == 'Multi-tool']\n",
    "\n",
    "if len(multi_tool_cases) > 0:\n",
    "    rprint(\"=\" * 60)\n",
    "    rprint(\"MULTI-TOOL ROUTING ANALYSIS\")\n",
    "    rprint(\"=\" * 60)\n",
    "    \n",
    "    multi_accuracy = multi_tool_cases['correct'].mean()\n",
    "    rprint(f\"\\nMulti-tool accuracy: {multi_accuracy * 100:.1f}%\")\n",
    "    rprint(f\"Cases: {multi_tool_cases['correct'].sum()}/{len(multi_tool_cases)} correct\")\n",
    "    \n",
    "    rprint(\"\\nMulti-tool test cases:\")\n",
    "    for _, row in multi_tool_cases.iterrows():\n",
    "        status = \"✓\" if row['correct'] else \"✗\"\n",
    "        rprint(f\"\\n{status} {row['query'][:60]}...\")\n",
    "        rprint(f\"  Expected: {row['expected_tools']}\")\n",
    "        rprint(f\"  Actual: {row['actual_tools']}\")\n",
    "        if not row['correct']:\n",
    "            rprint(f\"  Issue: {row['reasoning']}\")\n",
    "else:\n",
    "    rprint(\"No multi-tool test cases defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f523e9bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes and Observations\n",
    "\n",
    "**Key Findings:**\n",
    "- [Add observations after running tests]\n",
    "\n",
    "**Multi-Tool Coordination:**\n",
    "- [Note how well content planning agent handles queries needing multiple tools]\n",
    "\n",
    "**Potential Issues:**\n",
    "- [Note any patterns in failures, especially multi-tool cases]\n",
    "\n",
    "**Recommendations:**\n",
    "- [Suggestions for improvement if tests fail]\n",
    "\n",
    "---\n",
    "\n",
    "**Test completed:** [Date/Time auto-filled when run]\n",
    "\n",
    "**Next steps:** [Determined by pass/fail results]\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
