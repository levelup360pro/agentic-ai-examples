# Week 8: Hexagonal Architecture & Full Microsoft Agent Framework Adoption

**Status**: Complete âœ…
**Focus**: Framework-agnostic architecture through Ports & Adapters pattern, full Microsoft Agent Framework adoption, and enhanced research capabilities with fact-checking.

---

## Executive Summary

Week 8 represents a **strategic architectural evolution**: transitioning from the initial Microsoft Agent Framework implementation (Week 6) to a **full adoption of Agent Framework protocols** while preserving the framework-agnostic core that enables rapid project bootstrapping across different orchestration frameworks.

**Key Outcomes**:
- âœ… **Hexagonal Architecture**: Implemented Ports & Adapters pattern separating framework-agnostic core from orchestration-specific adapters.
- âœ… **Protocol-Based Dependency Injection**: Created LLMClientProtocol, VectorStoreProtocol, WebSearchProtocol enabling any implementation to satisfy core class dependencies.
- âœ… **Dual-Protocol LLM Adapter**: AgentFrameworkLLMAdapter implements both LLMClientProtocol (core) and ChatClientProtocol (Agent Framework), enabling unified observability.
- âœ… **Hexagonal Tools Architecture**: Separated tool business logic from framework decorators, enabling the same tool to work with both LangGraph (@tool) and Agent Framework (@ai_function).
- âœ… **Simplified Research Architecture**: Direct tool execution via ResearchExecutor instead of LLM-based research agent, reducing unnecessary LLM calls.
- âœ… **Fact-Check Mode**: Enhanced research capabilities with verification-focused queries and trusted source filtering.
- âœ… **Brand-Agnostic Configuration**: Search domain filters and fact-checking configuration moved to brand YAML configs.

**Architecture Achievement**: Built a **true Hexagonal (Ports & Adapters) Architecture** where the `core/` layer contains pure business logic with protocol-based type hints, the `infrastructure/` layer provides concrete implementations, and the `orchestration/` layer adapts these to framework-specific patterns. This enables switching orchestration frameworks (Agent Framework, LangGraph, CrewAI) without modifying core logic.

**Critical Discovery**: The Agent Framework's BaseChatClient provides built-in OpenTelemetry observability that our custom LLMClient lacks. By creating AgentFrameworkLLMAdapter that wraps LLMClient while implementing both LLMClientProtocol and ChatClientProtocol, we gain automatic OTEL telemetry without duplicating infrastructure.

**Production Readiness**: The architecture now supports **enterprise-ready patterns** including:
- Protocol-based dependency injection for testability
- Framework-agnostic core enabling vendor flexibility
- Built-in observability via Agent Framework's OTEL integration
- Fact-checking capabilities for regulated industries requiring verification
- Brand-specific configuration for multi-tenant deployments

---

## Design Decisions

### Decision 32: Hexagonal Architecture - Framework-Agnostic Core with Ports & Adapters

**Challenge**: Enable reuse of core business logic (ContentGenerator, Evaluators, PromptBuilder, RAGHelper) across different orchestration frameworks (Agent Framework, LangGraph, CrewAI) without rewriting.

**Discovery Process**:
Evaluated integration approaches:
- Tight coupling to Agent Framework: Fast implementation but vendor lock-in, no reuse across frameworks
- Framework-agnostic wrappers only: Preserves flexibility but loses full Agent Framework capabilities (multi-agent orchestration, MCP, observability)
- Ports & Adapters pattern: Industry-standard separation of concerns

**Solution**: **Hexagonal (Ports & Adapters) Architecture**.
- Core layer: Framework-agnostic business logic depending on protocols (interfaces)
- Infrastructure layer: Concrete implementations satisfying protocols
- Orchestration layer: Framework-specific adapters implementing protocols

**Rationale**:
- **Reusability**: Core logic works with any framework implementing the protocols.
- **Testability**: Protocol-based dependencies enable easy mocking.
- **Vendor Flexibility**: Switching frameworks = new orchestration folder, same core.
- **Future-Proofing**: As Agent Framework evolves, only adapters need updating.

**Impact**:
- Enables framework-agnostic core to be reused across orchestration implementations
- Allows core business logic to remain stable while orchestration adapters evolve independently
- Reduces future refactoring cost when switching or adding new frameworks

**Alternative Rejected**: Tight coupling to Agent Framework. Rejected because it creates vendor lock-in and prevents reuse of proven core logic across projects using different orchestration frameworks.

---

### Decision 33: Dual-Protocol LLM Adapter - LLMClientProtocol + ChatClientProtocol

**Challenge**: Core classes (ContentGenerator, ContentEvaluator, ContentPlanningAgent) depend on LLMClientProtocol (`get_completion()`) but Agent Framework requires ChatClientProtocol (`get_response()`). The original adapter only implemented ChatClientProtocol, preventing core classes from using Agent Framework's built-in OTEL observability.

**Discovery Process**:
Considered approaches to add observability:
- Add OpenTelemetry spans directly to LLMClient: Duplicates observability infrastructure already in BaseChatClient
- Create separate observable wrapper: Adds unnecessary layer between core and LLM
- Implement both protocols in single adapter: Clean, unified solution

**Solution**: **Dual-Protocol Adapter**.
- AgentFrameworkLLMAdapter implements both LLMClientProtocol and ChatClientProtocol
- Core classes call `get_completion()` (LLMClientProtocol)
- Agent Framework ChatAgents call `get_response()` (ChatClientProtocol)
- Single adapter instance serves all components with unified OTEL telemetry

**Rationale**:
- **Unified Observability**: All LLM calls, regardless of calling pattern, flow through Agent Framework's OTEL infrastructure.
- **No Code Duplication**: Single adapter replaces need for separate observable wrappers.
- **Explainability**: OTEL telemetry via `OTEL_PROVIDER_NAME` provides full audit trail required for regulated industries.

**Impact**:
- Unifies observability across all LLM invocation patterns (core classes and Agent Framework components)
- Eliminates need for duplicate observability infrastructure
- Provides OTEL telemetry for both framework-agnostic and framework-specific code paths

**Alternative Rejected**: Add OpenTelemetry spans directly to LLMClient. Rejected because it duplicates observability infrastructure already built into Agent Framework's BaseChatClient.

---

### Decision 34: Hexagonal Tools Architecture - Framework-Agnostic Core with Framework Adapters

**Challenge**: Tool invocation patterns differ fundamentally: LangGraph uses `@tool` from `langchain_core.tools` for ToolNode compatibility; Agent Framework uses `@ai_function` from `agent_framework`. A single tool definition cannot satisfy both decorators.

**Discovery Process**:
Evaluated tool architecture approaches:
- Single tool definition with both decorators: Incompatible - decorators conflict
- LangChain-only tools: Loses Agent Framework integration
- Separate tool files per framework: Duplicates business logic
- Tool factory pattern: Initial approach, but created tight coupling between frameworks

**Solution**: **Hexagonal Tools Architecture**.
- Core layer: Framework-agnostic implementations (`rag_search_core()`, `web_search_core()`) returning Dict results
- Adapter layer: Framework-specific decorators wrapping core logic
- LangGraph adapters: `@tool` decorated functions
- Agent Framework adapters: `@ai_function` decorated functions

**Rationale**:
- **Single Source of Truth**: Business logic lives in core; adapters are thin wrappers.
- **Framework Independence**: Adding new framework = new adapter, not rewriting tools.
- **Consistency**: Same search logic, same results, regardless of calling framework.

**Impact**:
- Tool business logic decoupled from framework-specific decorators
- Same tool implementation can serve multiple frameworks without code duplication
- Simplifies addition of new frameworks by reusing core tool functions

**Alternative Rejected**: Separate tool files per framework. Rejected because it duplicates business logic and creates maintenance burden when search behavior needs updating.

---

### Decision 35: Simplified Research Architecture - Direct Tool Execution Over LLM-Based Research Agent

**Challenge**: Avoid unnecessary LLM calls during research phase. The planner already decides which tools to use; creating a separate LLM-based ResearchChatAgent would duplicate that decision with an extra LLM call.

**Discovery Process**:
Considered research agent patterns:
- ResearchChatAgent (ChatAgent with tools): Adds LLM call for tool selection that planner already handles
- Hybrid Handoff pattern: Over-engineered for current use case
- Separate FactCheckAgent: Fact-checking is research with verification focus, not a distinct concern

**Solution**: **Enhanced ResearchExecutor with Direct Tool Execution**.
- ResearchExecutor executes tools directly based on planner's `PlanningDecision`
- No intermediate LLM call for tool selection
- Fact-check mode adds verification-focused queries and trusted source filtering
- Total LLM calls remain at 3 (planner â†’ generator â†’ evaluator)

**Rationale**:
- **Efficiency**: Eliminates redundant LLM call for tool selection.
- **Simplicity**: Single executor handles all research modes (RAG, web, fact-check).
- **Cost Control**: Fewer LLM calls = lower cost per workflow execution.

**Impact**:
- Reduces LLM call count from 4 to 3 per workflow execution
- Lowers cost and latency while maintaining full research capabilities
- Fact-check mode adds verification capabilities without additional LLM overhead

**Alternative Rejected**: ResearchChatAgent (ChatAgent with tools). Rejected because it adds an unnecessary LLM call that duplicates the planner's tool selection decision.

---

### Decision 36: Brand-Agnostic Configuration for Search and Fact-Checking

**Challenge**: LevelUp360 (B2B tech) and OssieNaturals (B2C cosmetics) need different trusted sources and verification query patterns. Hardcoding domain lists in code requires redeployment for config changes.

**Discovery Process**:
Evaluated configuration approaches:
- Hardcoded domain lists per brand in code: Config changes require code deployment
- Single global config: Doesn't support brand-specific requirements
- Brand YAML configs: Already established pattern from Week 6

**Solution**: **Brand YAML Configuration for Search Preferences**.
- Move `search_preferences` (include/exclude domains) to brand YAML
- Move `fact_checking` (trusted domains, verification suffixes) to brand YAML
- TavilySearchClient and ResearchExecutor read from brand config at runtime

**Rationale**:
- **Single Source of Truth**: Brand config YAML is already the source for voice, templates, models.
- **Runtime Configuration**: Config changes don't require code deployment.
- **Multi-Tenant Ready**: Each brand has independent search and verification settings.

**Impact**:
- Configuration changes no longer require code deployment
- Enables runtime customization of search behavior per brand
- Supports multi-tenant scenarios with independent search policies

**Alternative Rejected**: Hardcoded domain lists per brand in code. Rejected because configuration changes require code deployment and violates separation of concerns.

---

### Decision 37: Full Microsoft Agent Framework Adoption (Option A)

**Challenge**: Decide between wrapper-only approach (preserving existing patterns, adding observability manually) or full Agent Framework adoption (gaining multi-agent orchestration, MCP, observability, middleware, Azure Functions hosting).

**Discovery Process**:
Evaluated integration depth:
- Option B (Wrapper Approach): Add observability only via manual OpenTelemetry spans
- Option C (Hybrid): Start with B, migrate to A incrementally
- Option A (Full Adoption): Adopt Agent Framework protocols for all components

**Solution**: **Full Adoption of Agent Framework Protocols**.
- LLMClient wrapped by AgentFrameworkLLMAdapter(BaseChatClient)
- Agents implemented as ChatAgent instances calling portable core logic
- Workflows built with GroupChatBuilder or HandoffBuilder patterns
- Hosting via AgentFunctionApp for Azure Functions deployment

**Rationale**:
- **Ecosystem Alignment**: Strategic investment in Microsoft ecosystem pays off with unified tooling.
- **Multi-Agent Orchestration**: GroupChatBuilder, HandoffBuilder, MagenticBuilder unlock complex agent patterns.
- **MCP Integration**: Model Context Protocol server/client integration for tool interoperability.
- **Built-in Observability**: OTEL telemetry without custom instrumentation.
- **Azure Functions Hosting**: AgentFunctionApp enables serverless deployment.

**Impact**:
- Establishes architectural foundation for multi-agent patterns (GroupChatBuilder, HandoffBuilder)
- Enables Azure Functions deployment via AgentFunctionApp
- Positions framework for enterprise observability and multi-tenancy

**Alternative Rejected**: Wrapper-only approach (Option B). Rejected because it loses the significant capabilities Agent Framework provides: multi-agent orchestration, MCP integration, middleware pipeline, and seamless Azure Functions hosting.

---

### Decision 38: BlobConfigLoader for Brand Configuration Storage

**Challenge**: Azure Files requires storage account access keys (`shared_access_key_enabled=true`), but infrastructure sets `shared_access_key_enabled=false` for security. Need passwordless authentication for brand config storage.

**Discovery Process**:
Evaluated config storage options:
- Azure Files with access keys: Requires storing keys in Key Vault, violates "no keys anywhere" principle
- Bake configs into Docker image: Requires rebuild for config changes
- Azure Blob Storage with managed identity: Passwordless, supported by infrastructure

**Solution**: **BlobConfigLoader with Managed Identity**.
- Create BlobConfigLoader using `DefaultAzureCredential` for managed identity auth
- LocalConfigLoader fallback for local development
- Read brand YAMLs from `configs` container in storage account

**Rationale**:
- **Passwordless**: Managed identity eliminates credential management.
- **Existing Infrastructure**: Storage account and `configs` container already created by Terraform.
- **Development Parity**: LocalConfigLoader enables local development with same code path.

**Impact**:
- Eliminates need for credential storage in Key Vault for configuration access
- Enables configuration updates without image rebuilds
- Provides development parity between local and cloud environments

**Alternative Rejected**: Azure Files with access keys. Rejected because it requires storing keys in Key Vault, creating a security surface that violates the "no keys anywhere" principle established in Week 7.

---

## Architecture Overview

### Hexagonal Architecture Structure

**Three-Layer Separation**:
```
src/
â”œâ”€â”€ core/                              # Framework-Agnostic Business Logic (Ports)
â”‚   â”œâ”€â”€ protocols/                     # Protocol definitions (interfaces)
â”‚   â”‚   â”œâ”€â”€ llm.py                    # LLMClientProtocol, CompletionResultProtocol
â”‚   â”‚   â”œâ”€â”€ vector_store.py           # VectorStoreProtocol, QueryResultProtocol
â”‚   â”‚   â””â”€â”€ search.py                 # WebSearchProtocol, SearchResultProtocol
â”‚   â”œâ”€â”€ generation/                    # ContentGenerator (uses LLMClientProtocol)
â”‚   â”œâ”€â”€ evaluation/                    # ContentEvaluator (uses LLMClientProtocol)
â”‚   â”œâ”€â”€ prompt/                        # PromptBuilder (uses LLMClientProtocol)
â”‚   â””â”€â”€ rag/                           # RAGHelper (uses VectorStoreProtocol)
â”‚
â”œâ”€â”€ infrastructure/                    # Concrete Implementations (Adapters)
â”‚   â”œâ”€â”€ llm/                          # LLMClient (satisfies LLMClientProtocol)
â”‚   â”œâ”€â”€ rag/                          # VectorStore (satisfies VectorStoreProtocol)
â”‚   â””â”€â”€ search/                       # TavilySearchClient (satisfies WebSearchProtocol)
â”‚
â”œâ”€â”€ shared/tools/                      # Hexagonal Tools
â”‚   â”œâ”€â”€ core/                         # Framework-agnostic tool implementations
â”‚   â”‚   â”œâ”€â”€ rag_search.py             # rag_search_core() â†’ Dict
â”‚   â”‚   â””â”€â”€ web_search.py             # web_search_core() â†’ Dict
â”‚   â””â”€â”€ adapters/                     # Framework-specific decorators
â”‚       â”œâ”€â”€ langgraph/tools.py        # @tool decorated wrappers
â”‚       â””â”€â”€ agent_framework/tools.py  # @ai_function decorated wrappers
â”‚
â””â”€â”€ orchestration/                     # Framework-Specific Orchestration
    â”œâ”€â”€ microsoft_agent_framework/
    â”‚   â”œâ”€â”€ adapters/                 # AgentFrameworkLLMAdapter (dual-protocol)
    â”‚   â”œâ”€â”€ agents/                   # ChatAgent instances
    â”‚   â””â”€â”€ workflows/                # GroupChatBuilder pipelines
    â”œâ”€â”€ langgraph/                    # LangGraph StateGraph implementation
    â””â”€â”€ crewai/                       # CrewAI Flow implementation
```

### Dual-Protocol LLM Adapter Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AgentFrameworkLLMAdapter                         â”‚
â”‚                 (Implements Both Protocols)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ LLMClientProtocol â”‚         â”‚ ChatClientProtocol    â”‚           â”‚
â”‚  â”‚                   â”‚         â”‚ (BaseChatClient)      â”‚           â”‚
â”‚  â”‚ â€¢ get_completion()â”‚         â”‚ â€¢ get_response()      â”‚           â”‚
â”‚  â”‚ â€¢ get_embedding() â”‚         â”‚ â€¢ OTEL telemetry      â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚            â”‚                              â”‚                         â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                       â”‚                                             â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚              â”‚   LLMClient     â”‚                                   â”‚
â”‚              â”‚ (portable_client)â”‚                                   â”‚
â”‚              â”‚                 â”‚                                   â”‚
â”‚              â”‚ â€¢ Azure OpenAI  â”‚                                   â”‚
â”‚              â”‚ â€¢ OpenRouter    â”‚                                   â”‚
â”‚              â”‚ â€¢ OpenAI        â”‚                                   â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Usage:
  Core Classes â†’ get_completion() â†’ adapter â†’ portable_client â†’ LLM
  ChatAgents   â†’ get_response()   â†’ adapter â†’ portable_client â†’ LLM
                                         â†“
                              OTEL telemetry captured
```

### Hexagonal Tools Architecture

```
Tool Request from Workflow
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Framework Adapter Layer                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  LangGraph Adapter                   Agent Framework Adapter        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
â”‚  @tool                               @ai_function                   â”‚
â”‚  def rag_search_tool(query):         def rag_search_tool(query):   â”‚
â”‚      return rag_search_core(...)         return rag_search_core(...) â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Core Tool Layer                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  rag_search_core(query, brand, vector_store, ...) â†’ Dict           â”‚
â”‚  web_search_core(query, search_client, ...) â†’ Dict                 â”‚
â”‚                                                                     â”‚
â”‚  â€¢ Framework-agnostic                                               â”‚
â”‚  â€¢ Returns plain Dict (no framework types)                         â”‚
â”‚  â€¢ Contains all business logic                                      â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Testing & Validation

### Protocol Compliance Verification

**Objective**: Verify that concrete implementations satisfy protocol definitions.

**Test Methodology**:
- Static type checking with pyright/mypy
- Runtime protocol compliance tests

**Results**:
- âœ… LLMClient satisfies LLMClientProtocol
- âœ… VectorStore satisfies VectorStoreProtocol  
- âœ… TavilySearchClient satisfies WebSearchProtocol
- âœ… AgentFrameworkLLMAdapter satisfies both LLMClientProtocol and ChatClientProtocol

### Core Class Migration Verification

**Objective**: Verify core classes work with protocol-typed dependencies.

**Test Methodology**:
- Updated type hints to use protocols instead of concrete types
- Ran existing unit tests to verify no behavioral changes

**Results**:
- âœ… ContentGenerator: Works with LLMClientProtocol
- âœ… ContentEvaluator: Works with LLMClientProtocol
- âœ… RAGHelper: Works with VectorStoreProtocol
- âœ… PromptBuilder: Works with LLMClientProtocol

---

## What Worked

### 1. Ports & Adapters Pattern

**Approach**: Separating business logic from framework concerns through protocol-based dependency injection.

**Outcome**: Core classes remain untouched while gaining Agent Framework capabilities. The same ContentGenerator class works with LLMClient directly, through AgentFrameworkLLMAdapter, or with any future implementation satisfying LLMClientProtocol.

### 2. Dual-Protocol Adapter Design

**Approach**: Single adapter implementing both LLMClientProtocol (for core classes) and ChatClientProtocol (for Agent Framework).

**Outcome**: Unified observability across all LLM calls. Core classes using `get_completion()` and ChatAgents using `get_response()` both benefit from Agent Framework's built-in OTEL telemetry.

### 3. Hexagonal Tools with Core/Adapter Split

**Approach**: Tool business logic in framework-agnostic core functions, framework decorators in separate adapter modules.

**Outcome**: Same RAG search and web search logic works with both LangGraph and Agent Framework without code duplication.

---

## What Didn't Work

### 1. Initial Tool Factory Pattern

**Problem**: First attempt used factory functions that returned framework-specific tool instances, but this created tight coupling between the factory and framework types.

**Impact**: Factory had to import both `@tool` and `@ai_function` decorators, creating unnecessary dependencies.

**Correction**: Switched to hexagonal pattern with separate adapter modules. Core functions are pure Python; adapters handle framework-specific decoration.

### 2. ResearchChatAgent (LLM-Based Research)

**Problem**: Created a ChatAgent for research that would use LLM to decide tool invocation, but this duplicated the planner's tool selection logic.

**Impact**: Added unnecessary LLM call, increasing cost and latency.

**Correction**: Deleted ResearchChatAgent. Enhanced ResearchExecutor executes tools directly based on planner's decision. Fact-check mode adds verification capabilities without extra LLM calls.

---

## Lessons Learned

### 1. Protocols Enable Framework Flexibility Without Sacrificing Capabilities

**Discovery**: By defining protocols (interfaces) for core dependencies, we can swap implementations without changing business logic. The AgentFrameworkLLMAdapter adds observability and Agent Framework integration without modifying ContentGenerator or ContentEvaluator.

**Implication**: New orchestration frameworks can be added by creating new adapters in `orchestration/`. Core logic remains stable and reusable.

### 2. Fewer LLM Calls = Better Economics and Latency

**Discovery**: The planner already decides which tools to use. Adding a research agent to re-decide tool invocation is redundant.

**Implication**: Direct tool execution based on planner decisions keeps the workflow at 3 LLM calls (planner â†’ generator â†’ evaluator) while maintaining full research capabilities including fact-checking.

### 3. Configuration-Driven Behavior Enables Multi-Tenant Flexibility

**Discovery**: Moving search domain filters and fact-checking configuration to brand YAMLs enables per-brand customization without code changes.

**Implication**: Onboarding a new brand requires only YAML configuration; no code deployment needed for search behavior customization.

---

## Progress Against 12-Week Plan

### Month 2-3: Production Build (Weeks 5-8)

**Week 5**: âœ… Framework Evaluation (CrewAI rejected, Microsoft Agent Framework selected)
**Week 6**: âœ… Microsoft Agent Framework Build & UI (v1.0-reference completed)
**Week 7**: âœ… Azure Infrastructure & CI/CD (Terraform, GitHub Actions, Container Apps)
**Week 8**: ğŸ”„ **Hexagonal Architecture & Full Agent Framework Adoption**
- Implemented Ports & Adapters pattern for framework-agnostic core
- Created protocol definitions (LLMClientProtocol, VectorStoreProtocol, WebSearchProtocol)
- Built dual-protocol LLM adapter for unified observability
- Implemented hexagonal tools architecture
- Simplified research with direct tool execution
- Added fact-check mode with brand-specific configuration

**Week 9+**: ğŸ“… **Agent Framework Patterns & Observability**
- Refactor remaining agents to ChatAgent pattern
- Implement GroupChatBuilder or HandoffBuilder workflows
- AgentFunctionApp hosting for Azure Functions
- Application Insights dashboard integration

---

## Cost Summary

### Week 8 Costs

**Development & Testing**:
- **Protocol Migration Testing**: ~30 runs validating protocol compliance
- **Adapter Testing**: ~20 runs verifying dual-protocol behavior
- **Tool Architecture Testing**: ~15 runs validating hexagonal tool pattern
- **Fact-Check Testing**: ~10 runs testing verification mode

**Estimated Week 8 Total**: ~â‚¬2.00 (development) + ~â‚¬15.00 (Azure resources prorated)

**Cumulative Costs**:
- Week 1: â‚¬2.15
- Week 2: â‚¬8.60
- Week 3: â‚¬5.24
- Week 4: â‚¬2.41
- Week 5: ~â‚¬0.00
- Week 6: ~â‚¬3.50
- Week 7: ~â‚¬17.50
- Week 8: ~â‚¬17.00
- **Total**: ~â‚¬56.40

**Budget Status**: Within the â‚¬60/month budget. Architecture refactoring involved minimal LLM usage; costs primarily from Azure infrastructure.

---

## Blockers / Risks

### 1. Sync/Async Mismatch

**Issue**: LLMClient uses synchronous methods; Agent Framework expects async.

**Mitigation**: AgentFrameworkLLMAdapter wraps sync calls appropriately. For production, may need to implement async LLMClient methods.

### 2. Streaming Support

**Issue**: Agent Framework streaming support not yet implemented in LLMClient.

**Mitigation**: Placeholder `get_completion_stream()` method added to adapter. Full streaming implementation deferred to Week 9.

---

## Next Steps

### What Changed This Week

**Original Plan**: HITL integration (approval workflows), observability dashboards, and cost alerts for Week 8.

**What Actually Happened**: Hexagonal Architecture refactoring and full Agent Framework adoption took priority. This proved to be the right decision because:
- Refactoring unlocked **full end-to-end observability via Agent Framework's built-in OTEL integration** without custom instrumentation
- Framework-agnostic core created reusability path across multiple orchestration frameworks
- Dual-protocol adapter enables observability for both legacy and modern code paths

**Achieved This Week**: 
- âœ… **Full End-to-End Observability**: Agent Framework's BaseChatClient provides automatic OTEL telemetry for all LLM calls, tool invocations, and agent decisions. No custom dashboard or metric code neededâ€”telemetry is built-in.
- âœ… **Foundation for Multi-Tenancy**: Protocol-based architecture and brand-agnostic configuration enable independent search policies per tenant
- âœ… **Framework Flexibility**: Core logic now reusable across Agent Framework, LangGraph, and future frameworks

### Future Roadmap (Week 9+)

Week 9 focuses on **advanced orchestration and production deployment**:

1. **Multi-Agent Orchestration**: GroupChatBuilder or HandoffBuilder workflows for complex agent patterns
2. **Application Insights Integration**: Hook into automatic OTEL telemetry for dashboards, alerts, and custom metrics
3. **Azure Functions Hosting**: AgentFunctionApp deployment for serverless scaling

---


*Hexagonal architecture established. Framework-agnostic core preserved while gaining full Agent Framework capabilities.*
